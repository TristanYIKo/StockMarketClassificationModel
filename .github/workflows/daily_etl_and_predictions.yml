name: Daily ETL and Predictions

on:
  schedule:
    # Run at 5 PM EST (10 PM UTC) on weekdays only (Monday-Friday)
    # Markets close at 4 PM, so 5 PM gives time for data to settle
    # Stock markets are closed on weekends, so we skip Saturday (6) and Sunday (0)
    - cron: '0 22 * * 1-5'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Start date (YYYY-MM-DD, optional)'
        required: false
        type: string
      end_date:
        description: 'End date (YYYY-MM-DD, optional)'
        required: false
        type: string

jobs:
  etl-and-predict:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        cd ml
        pip install -r requirements.txt
    
    - name: Set up environment variables
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
      run: |
        echo "Environment variables configured"
        # Verify essential variables are set
        if [ -z "$SUPABASE_URL" ]; then
          echo "Error: SUPABASE_URL is not set"
          exit 1
        fi
        if [ -z "$SUPABASE_KEY" ]; then
          echo "Error: SUPABASE_KEY is not set"
          exit 1
        fi
        if [ -z "$FRED_API_KEY" ]; then
          echo "Error: FRED_API_KEY is not set"
          exit 1
        fi
    
    - name: Apply Database Migrations (if needed)
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        echo "Checking for pending migrations..."
        # Check if outcome_price columns exist, if not, apply migration
        python -c "
        from etl.supabase_client import SupabaseDB
        import os
        
        db = SupabaseDB()
        
        # Check if columns exist by querying
        try:
            result = db.client.table('daily_bars').select('outcome_price_1d').limit(1).execute()
            print('‚úÖ outcome_price columns already exist')
        except Exception as e:
            if 'outcome_price_1d' in str(e).lower() or 'column' in str(e).lower():
                print('‚ö†Ô∏è  outcome_price columns do not exist')
                print('üìù Migration 015 needs to be applied manually in Supabase SQL Editor')
                print('See migrations/015_add_outcome_prices.sql')
            else:
                print(f'‚úÖ Columns likely exist (error: {e})')
        " || echo "Migration check completed with warnings"
    
    - name: Run ETL Pipeline
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
      run: |
        echo "Starting ETL pipeline for all symbols (SPY, QQQ, IWM, DIA)..."
        echo "This will update OHLCV data, features, labels, and outcome prices to the most recent trading day"
        echo "Note: outcome_price_1d and outcome_price_5d will be NULL for current day until future data arrives"
        if [ -n "${{ github.event.inputs.start_date }}" ] && [ -n "${{ github.event.inputs.end_date }}" ]; then
          # Manual run with custom dates
          python run_etl.py --start ${{ github.event.inputs.start_date }} --end ${{ github.event.inputs.end_date }} --mode incremental
        elif [ -n "${{ github.event.inputs.start_date }}" ]; then
          # Manual run with start date only
          python run_etl.py --start ${{ github.event.inputs.start_date }} --mode incremental
        else
          # Scheduled run - incremental update to today (auto-detects last date in DB)
          python run_etl.py --mode incremental
        fi
        echo "‚úÖ ETL pipeline completed - all symbols updated to latest trading day with current close prices"
    
    - name: Generate Predictions for All Symbols
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        echo "Generating predictions for next available trading day..."
        echo "Processing all symbols: SPY, QQQ, IWM, DIA (1d and 5d horizons)"
        echo "Attempting to use trained XGBoost models for real predictions..."
        
        # Try real model predictions first, fall back to placeholder if models don't exist
        if [ -f "ml/artifacts/models/xgboost_1d/model.pkl" ] && [ -f "ml/artifacts/models/xgboost_5d/model.pkl" ]; then
          echo "‚úÖ Trained models found - using real model-based predictions"
          python generate_real_predictions.py
        else
          echo "‚ö†Ô∏è  Trained models not found - using placeholder predictions (55% UP)"
          echo "   To use real models: train and commit models to repository"
          python quick_add_predictions_all_symbols.py
        fi
        
        echo "‚úÖ Predictions generated for next trading day - all symbols updated"
    
    - name: Verify Data Update
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        echo "Verifying data updates..."
        python check_db_dates.py
        echo "Verification complete"
    
    - name: Summary
      if: always()
      run: |
        echo "=================================="
        echo "Daily ETL and Prediction Summary"
        echo "=================================="
        echo "Timestamp: $(date)"
        echo "Status: ${{ job.status }}"
        echo "=================================="
